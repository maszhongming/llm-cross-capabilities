<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Cross Capabilities of LLMs</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/tangram.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Law of the Weakest Link: Cross Capabilities of Large Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://maszhongming.github.io">Ming Zhong</a>*<sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.astonzhang.com/">Aston Zhang</a>*<sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/xuewei-wang-97a6b4190/">Xuewei Wang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/rayhou/">Rui Hou</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/wenhan-xiong-0a5984a3/">Wenhan Xiong</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://cs.stanford.edu/~cgzhu/">Chenguang Zhu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://czxttkl.github.io/">Zhengxing Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/liang-tan-6646a484/">Liang Tan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/xueying-bi/">Chloe Bi</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://ai.meta.com/people/209431298931133/mike-lewis/">Mike Lewis</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/sravyapopuri/">Sravya Popuri</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/sharan-narang/">Sharan Narang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/melanie-kambadur/">Melanie Kambadur</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/dhruv-mahajan-4397764/">Dhruv Mahajan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/edunov/">Sergey Edunov</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://hanj.cs.illinois.edu">Jiawei Han</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://lvdmaaten.github.io/">Laurens van der Maaten</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Llama Team, AI @ Meta,</span>
            <span class="author-block"><sup>2</sup>University of Illinois Urbana-Champaign</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://maszhongming.github.io/llm-cross-capabilities/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/facebookresearch/llm-cross-capabilities"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/MingZhong/crosseval"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>CrossEval Benchmark</span>
                </a>
              </span>
              <!-- Twitter Link. -->
              <span class="link-block">
                <a href="https://maszhongming.github.io/llm-cross-capabilities/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa-brands fa-x-twitter"></i>
                  </span>
                  <span>Twitter</span></a>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <div class="content has-text-justified">
          The development and evaluation of Large Language Models (LLMs) have primarily focused on individual capabilities. Typically, developers construct specialized datasets tailored to distinct abilities, and then train models by blending these data sources. However, this overlooks the intersection of multiple capabilities across different types of expertise that are often required for real-world tasks, which we term <strong>cross capabilities</strong>.
          <br><br>In this project, we systematically explore this concept of cross capabilities in LLMs step by step.
        </div>  
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">What is Cross Capability?</h2>
        <div class="content has-text-justified">
          <ul>
            <li><strong>Examples:</strong>
              <ul>
              <li>Consider a user prompt asking, <i>"Which direction has the total rainfall in Tokyo, Japan been trending over the past 10 years?"</i> Such a task requires the integration of tool use (web browsing) with analytical reasoning.</li>
              <li>When a developer provides HTML and JavaScript code and asks, <i>"Give me a basic understanding of what this web app does,"</i> the model must combine long-context comprehension with coding expertise.</li>
              </ul>
            </li>
            <li><strong>Definition:</strong>
              <ul>
              <li>We define these scenarios as <strong>cross capabilities</strong>—the intersection of multiple distinct capabilities across different types of expertise necessary to address complex, real-world tasks.</li>
              </ul>
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Taxonomy for Individual and Cross Capabilities</h2>
        <p align="center">
        <img src="./static/images/taxonomy.png" class="center">
        </p>
        <div class="content has-text-justified">
          <ul>
            We start by identifying seven core individual capabilities of LLMs and then pair them to form seven common cross capabilities, each supported by a manually constructed taxonomy.<br><br>
            <li><strong>Individual Capabilities:</strong>
              <ul>
              <li><i>English</i></li>
              <li><i>Reasoning</i></li>
              <li><i>Coding</i></li>
              <li><i>Image Recognition</i></li>
              <li><i>Tool Use</i></li>
              <li><i>Long Context</i></li>
              <li><i>Spanish</i></li>
              </ul>
            </li>
            <li><strong>Cross Capabilities:</strong>
              <ul>
              <li><i>Coding & Reasoning</i></li>
              <li><i>Image Recognition & Reasoning</i></li>
              <li><i>Tool Use & Coding</i></li>
              <li><i>Tool Use & Reasoning</i></li>
              <li><i>Long Context & Coding</i></li>
              <li><i>Spanish & Reasoning</i></li>
              <li><i>Spanish & Image Recognition</i></li>
              </ul>
            </li>
            <li><strong>Taxonomy:</strong>
              <ul>
              <li>As illustrated in the Figure, these taxonomies follow a hierarchical design: the root node represents either an individual or cross capability, with the next two layers (Level-1 and Level-2 categories) breaking these down into increasingly specific tasks.</li>
              <li>This framework clearly distinguishes between tasks that rely on an individual capability and those that demand the integration of multiple abilities, allowing for a comprehensive evaluation of LLMs across various scenarios.</li>
              </li>
              </ul>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">CrossEval: Benchmarking LLM Cross Capabilities</h2>
        <p align="center">
        <img src="./static/images/crosseval.png" class="center" width="75%">
        </p>
        <div class="content has-text-justified">
          <ul>
            <li>To benchmark the cross capabilities of LLMs, we introduce the CrossEval benchmark, which includes:</li>
            <ul>
            <li><strong>Prompts</strong>: 1,400 expert-annotated prompts, with 100 prompts per capability</li>
            <li><strong>Category</strong>: each prompt categorized by level 1 and 2 based on the taxonomy</li>
            <li><strong>Difficulty Level</strong>: 10% easy, 30% medium and 60% hard for each capability</li>
            <li><strong>Reference Examples</strong>:</li>
            <ul>
              <li>Responses: 3 model responses per prompt</li>
              <li>Expert reviews: 2 human ratings with explanations per model response</li>
              <li>A total of 4,200 model responses and 8,400 expert reviews</li>
            </ul>
            </ul>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Building LLM-based Evaluators</h2>
        <p align="center">
        <img src="./static/images/correlation.png" class="center" width="100%">
        </p>
        <div class="content has-text-justified">
          CrossEval is the largest meta-evaluation benchmark for measuring the correlation between LLM-based scoring and human judgments. With each prompt including 3 reference model responses and 6 human ratings, we can explore how to develop the most effective in-domain LLM evaluator for this benchmark.
          <ul>
          <li><strong>Prompting LLMs for Evaluation:</strong>
            <ul>
            <li><strong>Multi-reference-based prompting:</strong> When using LLM-as-a-Judge, up to two reference responses, along with their ratings and explanations, are provided as context. For instance, when evaluating the first response, the LLM can be given the other responses with their four ratings.</li>
            <li><strong>Point-deduction-based prompting:</strong> LLM-as-a-Judge paradigm tends to favor longer, more structured responses, which leads to inflated evaluation scores. To address this, instead of assigning scores directly, LLMs are instrusted to summarize issues in both reference examples and the response under evaluation, specifying point deductions.
            </ul>
          </li>
          <li><strong>Correlations between LLM ratings and human judgments:</strong>
            <ul>
            <li>Each LLM shows particular strengths in evaluating different capabilities.</li>
            <li>With our reference examples and prompting methods, LLM evaluators achieve a Pearson correlation of nearly 0.7 with expert annotators' judgments on CrossEval.</li>
            </ul>
          </li>
          </ul>
        </div>
        <p align="center">
        <img src="./static/images/ablation_reference.png" class="center" width="100%">
        </p>
        <div class="content has-text-justified">
          <ul>
          <li><strong>Ablation study on the number of reference examples:</strong></li>
            <ul>
              <li> As shown in the Figure, a clear trend emerges: as the number of reference examples increases, all three correlation metrics improve significantly.</li>
              <li>Notably, when evaluating new model responses in our benchmark, we provide all three reference examples, which could potentially lead to even higher correlations.</li>
            </ul>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{zhong2023seeking,
      title={Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective},
      author={Zhong, Ming and An, Chenxin and Chen, Weizhu and Han, Jiawei and He, Pengcheng},
      journal={arXiv preprint arXiv:2310.11451},
      year={2023}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-6">
        <div class="content">
          <p>
            The source code of this webpage is based on the <a href="https://github.com/nerfies/nerfies.github.io/">
              Nerfies</a> project webpage.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
